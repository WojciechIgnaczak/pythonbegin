# Wprowadzenie do BigData i analizy danych

## Relacyjne bazy danych w ekosystemie Big Data
Big Data tp ogromne zbiory danych ktore sa zbyt duze złożone i szybko zmieniajace sie aby mozna bylo przetwarzac je tradycyjnie

Charakterystyka Big Data opiera się na 4 głównych aspektach tzw. 4V:
Volume -objetosc: ogromna ilosc danych generowanych przez różne źródła

Velocity-predkosc: szybkosc z jaka dane sa generowane,zbierane i przetwarzane. wymaga to systemow zdolnych do przetwarzania strumieni danych w czasie

Variety-roznorodnosc: rozne typy danych ktore moga byc strukturalne,polstrukturalne,niestrukturalne

Veracity - prawdziwosc: jakosc i wiarygosnosc danych ktore moga byc szumem,niekompletne,błędne


## Rola relacyjnych baz w big data:
trwałe przechowywanie danych
transakcyjnosc
zapytania i analiza

## Integracja z narzedziami big data (hadoop, spark)
hadoop- prsechowywanie i przetwarzanie w rozproszonym srodowisku, moze byc transfer miedzy hadoop a rel baz dan

spark- Apache spark to silnik przetwarzanai danych w pamieci ktora obsluguje szybkie przetwarzanie duzych zbiorow danych. spark moze byc zintegrowany z rel baz dan poprzez konektory JDBC, umozliwiajac wydajne przetwarzanie i analize danych

## Zarzadzanie duzymi zbiorami danych w relacyjnych bazach danych
- indeksowanie : tworzenie indeksow dla kolumn czesto uzywanych 
- partycjonowanie
- replikacja
- kompriomowanie danych: uzywanie kompresji danych w celu zmniejszenia rozmiary

Integracja z systemami CRM i ERP
CRM customer relatioship managment
ERP enterprise resource planning
umożliwia wymiane danych miedzy systemami

Integracja z crm pozwala na lepsze zarzadzanie relacjami z klientami a z erp na efektywne zarzadzanie zasobami przedsiebiorstwa

Integracja z Hadoop
umozliwia analize danych w konteksie transakcyjnuch

z Spark
do przetwarzenia danych w czasie rzeczywistym i analizy danych

z PolyBase 
do wykonywna zapytan mssql bezposrednio na danych przechoywanych w hadoop i

Zwiększona efektywnosc operacyjna
centralizacja i integracja z różnymi systemami 

Automatyzacja procesów raportowania i analizy danych


# ETL
Extract Transform Load
wydobycie, transformacja,ładowanie

Extract - polega na wydobywaniu danych z roznych zrodel

Transform- etap w kktorym dane sa przeksztalcane u przygotowywane do zaladowanie. Transformacja moze obejmowac czyszczenie danych, filtrowanie,agregacje,wzbogacanie, konwersje formatów

Load- Ostateczny etap w którym przetworzone dane są ładowane do docelowego systemu, w którym moze byc hurtownia danych, baza danych, system analityczny lub inne miejsce przechowywania danych

ETL:
Integracja danych
jakość danych

znaczenie etl
zarzadzanie duzymi wolumenami danych
automatyzacja procesow
wsparcie dla analiz biznesowych

Hurtownie danych:
firmy gromadza dane z roznych systemow tj ERP CRMM systemy ksiegowe

Migracje:
pobieranie z innych sys bazo dan

Integracja danych z chmurami:
wydobycie danych transformowanie ic
pozwala na analize danych i raportowanie


Analiza danych:
statystyki, dane marketingowe


SSIS- narzedzie etl

wszystko w managment studio
bogaty interfejs
duza funkcjonalnosc
rozszerzalnosc

ograniczona skalowalnosc
koszty



# data science
łaczy statystyke informatyle i biznes
gromadzenie przetwarzanie analiza interpretacja duzych i zlozonych zbiorow danych

wspiera biznez,przewidywania trendow,optymalizacja projektow,rozwiazywanie problemow poprzez wykorzystanie metod analitycnych i algorytmow uczenia maszynowego

elementy:
eksploracja sanych
modelowanie predykcyjne
wizualizacja danych
automatyzacja procesów
